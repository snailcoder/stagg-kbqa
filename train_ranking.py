#!/usr/bin/env python3
# -*- coding: utf-8 -*-


import os
import argparse

import torch
from torch.utils.data import DataLoader
import torch.nn.functional as F
import pandas as pd

import rank_model
import datasets
import config
import metrics
import utils

parser = argparse.ArgumentParser(
    description='Train LambdaRank model for computing query-answer pair score, '
                'based on features generated by infer chain and entity linking models.')
parser.add_argument('entity_linking_file',
                    default='data/webquestions.examples.train.e2e.top10.filter.sid.tsv',
                    help='original entity linking file: '
                         'webquestions.examples.train.e2e.top10.filter.sid.tsv')
parser.add_argument('qep_file',
                    default='data/webquestions.examples.train.e2e.top10.filter.q_ep.sid.tsv',
                    help='original qep file:'
                         'webquestions.examples.train.e2e.top10.filter.q_ep.sid.tsv')
parser.add_argument('matching_score_file',
                    default='data/matching_scores.txt',
                    help='containing patchain and qep scores generated by predict.py')
parser.add_argument('save_dir', default='models', help='directory to save ranking model')
parser.add_argument('--log_interval', type=int, default=100,
                    help='print training log every interval batches')

args = parser.parse_args()

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using {} device'.format(device))

dataset = datasets.RankingDataset(args.entity_linking_file,
                                  args.qep_file, args.matching_score_file)

config = config.RankerConfig()
model = rank_model.LambdaRank(config).to(device)

train_size = int(config.train_size * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])

def collate_batch(batch):
  feature = torch.FloatTensor(batch[0][0])
  feature = F.normalize(feature, p=2., dim=1)
  label = torch.FloatTensor(batch[0][1]).unsqueeze(1)
  return feature, label

train_dataloader = DataLoader(train_dataset, batch_size=1, collate_fn=collate_batch)
test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_batch)

optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)

def train_loop(dataloader, model, optimizer):
  size = len(dataloader.dataset)
  for batch, (x, y_true) in enumerate(dataloader):
    optimizer.zero_grad()
    x = x.to(device)
    y_true = y_true.to(device)
    y_score = model(x)
    lambdas = model.get_lambda_for_one_query(y_true, y_score)
    y_score.backward(lambdas)
    optimizer.step()

    if batch > 0 and batch % args.log_interval == 0 or batch == size - 1:
      ndcg_score = metrics.ndcg_score(y_true.view((1, -1)), y_score.view((1, -1))).item()
      loss = metrics.ranknet_loss(y_true.view((1, -1)), y_score.view((1, -1))).item()
      print(f'NDCG score: {ndcg_score:>7f}\tLoss: {loss:>7f}\t[{batch:>6d}/{size:>6d}]')

def test_loop(dataloader, model):
  loss, ndcg = 0, 0
  with torch.no_grad():
    for x, y_true in dataloader:
      x = x.to(device)
      y_true = y_true.to(device)
      y_score = model(x)
      loss += metrics.ranknet_loss(y_true.view((1, -1)), y_score.view((1, -1))).item()
      ndcg += metrics.ndcg_score(y_true.view((1, -1)), y_score.view((1, -1))).item()

  loss /= len(dataloader.dataset)
  ndcg /= len(dataloader.dataset)
  print(f'Test Avg Loss: {loss:>7f}\tNDCG score: {ndcg:>7f}')
  return ndcg

best_ndcg = 0
for t in range(config.epochs):
  print(f"Epoch {t+1}\n-------------------------------")
  train_loop(train_dataloader, model, optimizer)
  ndcg = test_loop(test_dataloader, model)
  if ndcg > best_ndcg:
    best_ndcg = ndcg
    utils.save_model(model, args.save_dir, 'rank_best_model.pth')
    print(f'Best NDCG score: {ndcg:>7f}\n')

print(f'Global best NDCG score: {best_ndcg:>7f}')

